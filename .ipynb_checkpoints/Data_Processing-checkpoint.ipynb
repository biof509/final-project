{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires the latest pip\n",
    "# !pip3 install --user --upgrade pip\n",
    "\n",
    "# Current stable release for CPU and GPU\n",
    "# !pip3 install --user tensorflow\n",
    "# !pip3 install --user keras\n",
    "\n",
    "# conda install -c conda-forge keras tensorflow\n",
    "# conda update -n base -c defaults conda\n",
    "#!conda install -c conda-forge jupyterthemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip file with all images and labels\n",
    "# filename = 'cifar-10-python.tar.gz'\n",
    "# tar = tarfile.open(filename, 'r:gz')\n",
    "# tar.extractall()\n",
    "# tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "projectpath = Path.cwd().absolute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out what is in the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to unpack the data into a dictionary\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding = 'bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'batch_label', b'labels', b'data', b'filenames']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirpath   = os.path.join(projectpath, 'cifar-10-batches-py')\n",
    "batchpath = os.path.join(dirpath, 'data_batch_1')\n",
    "batch     = unpickle(batchpath)\n",
    "\n",
    "# what are the key types\n",
    "list(batch.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rows = images, columns = pixels in an image\n",
    "batch[b'data'].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back calculating the shape of the image\n",
    "n_channels = 3\n",
    "n_imgs = batch[b'data'].shape[0]\n",
    "img_dim = int(np.sqrt(batch[b'data'].shape[1]/n_channels))\n",
    "\n",
    "train_data = batch[b'data'].reshape((n_imgs, n_channels, img_dim, img_dim)).transpose(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the images\n",
    "train_data = (train_data / 255) - 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process all batches and form into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the labels (could have just used keras.utils to_categorical)\n",
    "def one_hot_encode(train_labels):\n",
    "    encoded = np.zeros((n_imgs, len(np.unique(train_labels))))\n",
    "    for idx,lbl in enumerate(train_labels,0):\n",
    "        encoded[idx][lbl] = 1\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data comes in vectors so reshape then normalize\n",
    "def reshape_data(batchdata):\n",
    "    # reshape\n",
    "    n_channels = 3\n",
    "    n_imgs     = batchdata.shape[0]\n",
    "    img_dim    = int(np.sqrt(batchdata.shape[1]/n_channels))\n",
    "    train_data = batchdata.reshape((n_imgs, n_channels, img_dim, img_dim)).transpose(0, 2, 3, 1)\n",
    "    # normalize\n",
    "    train_data = (train_data / 255) - 0.5\n",
    "    return train_data, img_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack the data from the batches, do a bunch of stuff, then combine them\n",
    "batchpath  = os.path.join(projectpath, 'cifar-10-batches-py')\n",
    "\n",
    "for set in range(1,6):\n",
    "    if set == 1:\n",
    "        dirname       = os.path.join(batchpath, 'data_batch_' + str(set))\n",
    "        batch         = unpickle(dirname)\n",
    "        train_data, n = reshape_data(batch[b'data'])        \n",
    "        train_labels  = one_hot_encode(batch[b'labels'])\n",
    "    else:\n",
    "        dirname        = os.path.join(batchpath, 'data_batch_' + str(set))\n",
    "        batch          = unpickle(dirname)\n",
    "        train_data2, n = reshape_data(batch[b'data'])\n",
    "        train_labels2  = one_hot_encode(batch[b'labels'])\n",
    "        train_data     = np.concatenate((train_data, train_data2))\n",
    "        train_labels   = np.concatenate((train_labels, train_labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack the data from test batch, manipulate\n",
    "batchpath          = os.path.join(projectpath, 'cifar-10-batches-py')\n",
    "dirname            = os.path.join(batchpath, 'test_batch')\n",
    "testbatch          = unpickle(dirname)\n",
    "test_data, img_dim = reshape_data(testbatch[b'data'])        \n",
    "test_labels        = one_hot_encode(testbatch[b'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPool2D, BatchNormalization, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, \n",
    "                 kernel_size = 3, \n",
    "                 activation  = 'relu', \n",
    "                 padding     = 'same', \n",
    "                 input_shape = (img_dim,\n",
    "                                img_dim,\n",
    "                                3)))\n",
    "model.add(MaxPool2D(2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(32,\n",
    "                 kernel_size = 5, \n",
    "                 activation  = 'relu',\n",
    "                 padding     = 'same'))\n",
    "model.add(MaxPool2D(2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64,\n",
    "                 kernel_size = 3))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, \n",
    "                 activation='relu',\n",
    "                 kernel_size = 3))\n",
    "model.add(MaxPool2D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense  (64,  activation='relu'))\n",
    "model.add(Dense  (128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense  (64,  activation='relu'))\n",
    "model.add(Dense  (10,  activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience = 15,\n",
    "                                       restore_best_weights = True)\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss      = 'categorical_crossentropy', \n",
    "              metrics   = ['accuracy'])\n",
    "\n",
    "training = model.fit(train_data, \n",
    "                     train_labels, \n",
    "                     validation_split = 0.2, \n",
    "                     epochs = 100, \n",
    "                     batch_size = 125,\n",
    "                     callbacks = [early_stopping_monitor])\n",
    "\n",
    "#model.save('model_saved9.h5')\n",
    "\n",
    "plt.plot(training.history['loss'])\n",
    "plt.plot(training.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Model Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code that produced figures in the project presentation included below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axs[0].plot(training.history['loss'])\n",
    "axs[0].plot(training.history['val_loss'])\n",
    "axs[0].set_title('Loss')\n",
    "axs[1].plot(training.history['accuracy'])\n",
    "axs[1].plot(training.history['val_accuracy'])\n",
    "axs[1].set_title('Accuracy')\n",
    "\n",
    "fig.subplots_adjust(top = 0.8, bottom = 0.1, hspace = 0.5, wspace = 0.5)\n",
    "plt.show()\n",
    "fig.savefig('loss&accuracyModel9.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get shape of kernel and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = model.layers[0]\n",
    "weights1 = conv1.get_weights()\n",
    "kernels1 = weights1[0]\n",
    "kernels1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels1_1 = kernels1[:,:,:,0]\n",
    "kernels1_1\n",
    "kernels1_1avg = np.mean(kernels1_1, axis=0)\n",
    "\n",
    "plt.imshow(kernels1_1avg);\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function that performs a convolution with a kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(kernel, image):\n",
    "    img_dim     = image.shape[0]\n",
    "    channels    = image.shape[2]\n",
    "    kernel_size = kernel.shape[0]\n",
    "    output_size = img_dim-(kernel_size-1)\n",
    "    conv        = np.zeros((output_size,output_size))\n",
    "    \n",
    "    for ii in range(output_size):\n",
    "        for jj in range(output_size):\n",
    "            window = image[ii:ii+kernel_size, jj:jj+kernel_size]\n",
    "            conv[ii,jj] = np.sum(window*kernel)\n",
    "            \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the convolution function on random images to see its output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = train_data[25,:,:,:]\n",
    "conv = convolution(kernels1_1, image)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 8))\n",
    "axs[0].set_title('Original Image')\n",
    "axs[0].imshow(image);\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].set_title('Convolution Output')\n",
    "axs[1].imshow(conv);\n",
    "axs[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the output of 2 kernels on 2 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the kernels in RGB\n",
    "\n",
    "conv1    = model.layers[0]\n",
    "weights1 = conv1.get_weights()\n",
    "kernels1 = weights1[0] # shape of 32 kernels (3, 3, 3, 32)\n",
    "\n",
    "kernels1_1 = kernels1[:,:,:,16]\n",
    "kernels1_1avg = np.mean(kernels1_1, axis=0)\n",
    "\n",
    "kernels1_2 = kernels1[:,:,:,17]\n",
    "kernels1_2avg = np.mean(kernels1_2, axis=0)\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(8, 8))\n",
    "axs[0,0].imshow(kernels1_1[:,:,0], cmap=plt.cm.get_cmap('Reds', 6));\n",
    "axs[0,0].axis('off');\n",
    "axs[0,1].set_title('Kernel 1: edges?')\n",
    "axs[0,1].imshow(kernels1_1[:,:,1], cmap=plt.cm.get_cmap('Greens', 6));\n",
    "axs[0,1].axis('off');\n",
    "axs[0,2].imshow(kernels1_1[:,:,2], cmap=plt.cm.get_cmap('Blues', 6));\n",
    "axs[0,2].axis('off');\n",
    "\n",
    "axs[1,0].imshow(kernels1_2[:,:,0], cmap=plt.cm.get_cmap('Reds', 6));\n",
    "axs[1,0].axis('off');\n",
    "axs[1,1].set_title('Kernel 2: horizontal?')\n",
    "axs[1,1].imshow(kernels1_2[:,:,1], cmap=plt.cm.get_cmap('Greens', 6));\n",
    "axs[1,1].axis('off');\n",
    "axs[1,2].imshow(kernels1_2[:,:,2], cmap=plt.cm.get_cmap('Blues', 6));\n",
    "axs[1,2].axis('off');\n",
    "\n",
    "fig.subplots_adjust(top = 0.7, bottom = 0.1, hspace = 0.1, wspace = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the output of the kernels after convolving on 2 images\n",
    "\n",
    "image1 = train_data[1,:,:,:]\n",
    "image2 = train_data[50,:,:,:]\n",
    "conv1 = convolution(kernels1_1, image1)\n",
    "conv2 = convolution(kernels1_1, image2)\n",
    "conv3 = convolution(kernels1_2, image1)\n",
    "conv4 = convolution(kernels1_2, image2)\n",
    "\n",
    "fig, axs = plt.subplots(2, 4, figsize=(14, 14))\n",
    "axs[0,0].set_title('Original Image')\n",
    "axs[0,0].imshow(image1);\n",
    "axs[0,0].axis('off');\n",
    "\n",
    "axs[0,1].set_title('Convolution Output')\n",
    "axs[0,1].imshow(conv1);\n",
    "axs[0,1].axis('off');\n",
    "\n",
    "axs[0,2].set_title('Original Image')\n",
    "axs[0,2].imshow(image2);\n",
    "axs[0,2].axis('off');\n",
    "\n",
    "axs[0,3].set_title('Convolution Output')\n",
    "axs[0,3].imshow(conv2);\n",
    "axs[0,3].axis('off');\n",
    "\n",
    "axs[1,0].set_title('Original Image')\n",
    "axs[1,0].imshow(image1);\n",
    "axs[1,0].axis('off');\n",
    "\n",
    "axs[1,1].set_title('Convolution Output')\n",
    "axs[1,1].imshow(conv3);\n",
    "axs[1,1].axis('off');\n",
    "\n",
    "axs[1,2].set_title('Original Image')\n",
    "axs[1,2].imshow(image2);\n",
    "axs[1,2].axis('off');\n",
    "\n",
    "axs[1,3].set_title('Convolution Output')\n",
    "axs[1,3].imshow(conv4);\n",
    "axs[1,3].axis('off');\n",
    "\n",
    "fig.subplots_adjust(top = 0.5, bottom = 0.1, hspace = 0.1, wspace = 0.1)\n",
    "plt.show()\n",
    "fig.savefig('conv_output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a summary of the model's architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience = 15)\n",
    "\n",
    "score = model.evaluate(test_data, \n",
    "                       test_labels,\n",
    "                       callbacks = [early_stopping_monitor], \n",
    "                       batch_size = 125)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hand calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output              = model.predict_classes(test_data)\n",
    "predictions         = one_hot_encode(output)\n",
    "\n",
    "correct_predictions = (predictions * test_labels).sum()\n",
    "test_accuracy       = correct_predictions/len(predictions)\n",
    "\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance per category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cat      = np.sum(predictions, \n",
    "                       axis=0)\n",
    "corr_pred_cat = np.sum(predictions * test_labels,\n",
    "                       axis=0)\n",
    "true_cat      = np.sum(test_labels, \n",
    "                       axis=0)\n",
    "prob_cat      = corr_pred_cat/true_cat\n",
    "\n",
    "x = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "     'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.xticks(rotation=45);\n",
    "plt.bar(x, prob_cat);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Directions\n",
    "<font size=\"3.7\"> \n",
    "1. Explore the output of later convolutional layers\n",
    "    \n",
    "2. Investigate mistakes (confusions)\n",
    "   \n",
    "3. Compare mistakes with those of previous networks   \n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
